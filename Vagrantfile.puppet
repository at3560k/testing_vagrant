# -*- mode: ruby -*-
# vi: set ft=ruby :

Vagrant.configure("2") do |config|

  # Every Vagrant virtual environment requires a box to build off of.
  config.vm.box = "precise64"
  config.vm.box_url = "http://files.vagrantup.com/precise64.box"

  # cache buckets auto detection for vagrant-cachier
  #   verified working with vagrant-cachier (0.1.0)
  config.cache.auto_detect = true 

  # Note: host only networks mean no ports are blocked at all.
  #  10.11.12/24 is vbox hostonlyif vboxnet0  on dev host
   
  # We need to run our updater in apt first or packages fail
  config.vm.provision :shell, :path => "shell/bootstrap.sh"

  # Okay, this is a bit weird.  We add a provisioner for all VMs That points to
  # a submodule locally.  Which basically forces some writes to the hostfile so
  # puppet and newly created systems can talk to each other without
  # me building a custom nameserver...
  #
  # This will go away once we actually have hostnames or internal NS
  config.vm.provision :puppet do |puppet|
      # looks in manifests/default.pp automagically
      puppet.module_path = "modules"
      # Force a manual hostsfile out so these talk without using ipaddr
      puppet.manifest_file = "patchhosts.pp"
  end
 

  #####################################
  # Puppet server - local
  #####################################
  config.vm.define :puppetmaster do |pp_config|
    pp_config.vm.hostname = "puppet.test.edac.unm.edu"
    pp_config.vm.network :private_network, ip: "10.11.12.100"

    # Hey dog, I heard you like puppet so I provisioned puppet with your puppet
    pp_config.vm.provision :puppet do |puppet|
      # Local manifest, puppet apply
      puppet.manifests_path = "manifests"
      puppet.manifest_file = "puppet.pp"
      # Module path for remote module we'll add in
      puppet.module_path = "modules"
    end
  end

  #####################################
  # dbase - via puppet master
  #####################################
  config.vm.define :dbase do |db_config|
    db_config.vm.hostname = 'dbserver.test.edac.unm.edu'
    db_config.vm.network :private_network, ip: "10.11.12.211"
    # Relay PG to localhost.  This may not work nicely if you have a mismatched client version
    db_config.vm.network :forwarded_port, guest: 5432, host: 5432

    # Remote server
    db_config.vm.provision :puppet_server do |puppet|
      #puppet.options = ["--verbose", "--debug"]
      puppet.puppet_server = "puppet.test.edac.unm.edu"
    end
  end


  #####################################
  # mongo team
  #####################################
  
  # It's not that we need puppet to do this, so much as I need a way for the
  # hosts to communicate with each other by hostname and keep this organized
  # by something not ipaddr
  # 
  # vagrant up /mongo_*/

  #####################################
  # ansible driver
  #####################################

  # named so it's part of our mongo regex...
  config.vm.define :mongo_ansible do |ans_config|
    ans_config.vm.hostname = 'ansible.test.edac.unm.edu'
    ans_config.vm.network :private_network, ip: "10.11.12.101"

    # Forward our agent to this machine so I don't have to handle key
    # distribution on the images
    #
    config.ssh.forward_agent = true
    #  Note, we also install the pub key by vagrant's out of the box insecure key
    #  http://github.com/mitchellh/vagrant/raw/master/keys/vagrant.pub (rename
    #  to insecure_private_key.pub)
    #  And add this to my locally running agent (which is forwarded over to the
    #  vagrant box only for command & control purposes)

    # Okay, I want to avoid risking 'infrastructure'...
    #   And I'm not putting ansible on my desktop until I trust it not to
    #   install 1000 modules that will fetch a whole git tree...
    #
    ans_config.vm.provision :puppet do |puppet|
       # thick irony is thick
       puppet.module_path = "modules"
       puppet.manifest_file = "ansible.pp"  
    end
  end

  #####################################
  # mongo1:4 - via ansible master, with puppet help
  #####################################

  numMongo = 4
  ipAddrPrefix = "10.11.12.220"

  1.upto(numMongo) do |num|
    nodeName = ("mongo_n" + num.to_s).to_sym
    config.vm.define nodeName do |node|
      node.vm.hostname = 'mongo' + num.to_s + '.mongo.edac.unm.edu'
      node.vm.network :private_network, ip: ipAddrPrefix + num.to_s
      #node.vm.name = "Mongo Server: " + num.to_s

      #  ansible.playbook = "deployment/www.yml"
      #  ansible.inventory_file = "deployment/hosts"
    end
  end

  #####################################
  # Salt base box
  #####################################
  config.vm.define :salt do |salt_config|
    ans_config.vm.hostname = 'salt.test.edac.unm.edu'
    ans_config.vm.network :private_network, ip: "10.11.12.103"
    config.ssh.forward_agent = true

    # TODO: puppet in pip, salt, ssh agent
  end

end

